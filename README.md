<img  align="right" width="150" style="float: right;" src="https://www.upm.es/sfs/Rectorado/Gabinete%20del%20Rector/Logos/UPM/CEI/LOGOTIPO%20leyenda%20color%20JPG%20p.png">

<br/>

# RDSV - PR√ÅCTICA FINAL - Grupo 6

Repositorio de la pr√°ctica final de la asignatura RDSV - Curso 2022/2023.<br/>
Versi√≥n: 21 de diciembre de 2022.

## Autores ‚úíÔ∏è

* **Adri√°n Callejas Zurita** - [acallejasz](https://github.com/acallejasz)
* **Javier Vel√°zquez Mart√≠nez** - [jvelazquezm](https://github.com/jvelazquezm)
* **Sara Docasar Moreno** - [saradocasar](https://github.com/saradocasar)

## Descripci√≥n del proyecto üìã

Esta secci√≥n trata de poner una visi√≥n general sobre el contenido y desarrollo seguido en la realizaci√≥n de la pr√°ctica. En primer lugar, hay que tener claro que servicio de red objeto de estudio es el servicio residencial de acceso a Internet, donde el router residencial se sustituye por un ‚ÄòBridged Residential Gateway (BRG)‚Äô que realiza la conmutaci√≥n de nivel 2 del tr√°fico de los usuarios entre la red residencial y la central local. El resto de las funciones se realizan en la central local aplicando t√©cnicas de NFV, creando un servicio de CPE virtual (vCPE) gestionado mediante la plataforma de orquestaci√≥n. Para implementarlo se ha utilizado la RDSV2022-v1.ova, que virtualiza RDSV-K8S y RDSV-OSM, que nos permite utilizar el paquete microk8s, la herramienta VNX, Open vSwitch (ovs) y el entorno OSM, al que se accede gr√°ficamente.

De este modo, el uso de las diferentes tecnolog√≠as y conectividad ha sido el siguiente: la tecnolog√≠a VXLAN se ha usado para enviar encapsuladas en datagramas UDP las tramas de nivel 2 que viajan entre brg1, KNF:access y KNF:cpe. Para permitir esta comunicaci√≥n, tanto el brg1 como KNF:access tienen interfaces en AccessNet1, configuradas con direcciones IP del prefijo 10.255.0.0/24. La asignaci√≥n de direcciones IP a KNF:access y KNF:cpe en la red que las interconecta est√° gestionada por OSM y k8s, de manera que se asignan din√°micamente.
Antes de comenzar con la pr√°ctica se ha realizado el proceso de instalaci√≥n, con las pruebas de conectividad necesarias, as√≠ como la descarga del repositorio de la pr√°ctica y el compartido y el arranque y configuraci√≥n de los escenarios VNX. Tras esto, se ha definido el cl√∫ster k8s en OSM, donde se a almacenado una variable de entorno con el valor del namespace que va a utilizar OSM en el cl√∫ster para desplegar los pods de los servicios de red. 

Finalmente, durante la realizaci√≥n de la pr√°ctica, se han llevado a cabo la realizaci√≥n de una serie de mejoras m√≠nimas y opcionales que se incluyen a continuaci√≥n. Tambi√©n se indica como esta compuesto el repositorio y la funcionalidad de cada parte.

### Requisitos m√≠nimos ‚öôÔ∏è

- Sustituir el switch de KNF:access por un conmutador controlado por OpenFlow.
- Conectividad IPv4 desde la red residencial hacia Internet. Uso de doble NAT: en KNF:cpe y en isp1.
- Activar la captura de tr√°fico ARP mediante ‚Äúarpwatch‚Äù.
- Gesti√≥n de la calidad de servicio en la red de acceso mediante la API REST de Ryu controlando KNF:access, para limitar el ancho de banda de bajada hacia la red residencial. Debe ser independiente de la direcci√≥n IP asignada por DHCP a hX1 y hX2.
- Despliegue para dos redes residenciales.
- Todo automatizado mediante OSM y scripts, incluyendo el on-boarding de NS/VNFs y la instanciaci√≥n de NS mediante l√≠nea.
de comandos

### Requisitos opcionales ‚öôÔ∏è

- Utilizar un repositorio privado de im√°genes Docker: MicroK8s.
- Sustituir el switch de brgX por un conmutador controlado por OpenFlow desde el Ryu, incluyendo la gesti√≥n de la calidad de servicio desde el Ryu instalado en KNF:access y controlandolo para limitar el ancho de banda de subida desde la red residencial. Debe ser independiente de la direcci√≥n IP asignada por DHCP a hX1 y hX2.
- Instalar la funcionalidad arpwatch en un tercer contenedor, modificando los descriptores de OSM y creando un nuevo Helm char.

## Estructura del repositorio üß±

- Directorio **helm**: Contiene los helm charts: cpe, access y arpwatch, con la imagen del repositorio modificada. Sobre los ya proporcionados, se ha a√±adido uno nuevo para el requisito opcional de arpwatch en un nuevo contenedor, con todos los archivos y configuraci√≥n necesaria (values.yaml, chart.yaml y templates).
- Directorio **img**: Contiene los ficheros necesarios para construir la imagen de Docker y poder subirla al DockerHub, as√≠ como el propio Dockerfile con el que se compila la imagen, con los cambios pertinentes para cumplir con los requisitos presentados.
- Directorio **pck**: Contiene las descripciones de las funciones de red de cada uno de los helm charts (cpe, access y arpwatch), del servicio de red de la instancia de renes (modificado para el arpwatch) y los archivos comprimidos que se a√±adir√°n a OSM.
- Directorio **vnx**: Contiene las especificaciones xml para desplegar las redes residenciales y el servidor en la m√°quina de RDSV-K8s mediante vnx, con las modificaciones realizadas para cumplir con los requisitos.
- Archivos **.tgz**: Necesarios para que OSM los descargue al indicar la direcci√≥n de nuestro repositorio Helm, junto con el index.yaml configurado en las pages de este repositorio, tras haberlos empaquetado y actualizado previamente con Helm.
- Archivos **.sh**: Necesarios para desplegar, configurar y destruir en ambas m√°quinas virtuales el escenario completo con todas las mejoras realizadas y de manera automatizada.

## Arquitectura del escenario üõ†Ô∏è	

A continuaci√≥n se presenta el escenario final que se ha desplegado, que cuenta con los siguientes componentes:

- Cuatro sistemas finales hX1 y hX2 en casa del usuario, conectados al brgX que, a trav√©s de la red de acceso AccessNet se conectan a su vez a la central local, donde el servicio de red residencial se ofrece por dos VNF implementadas mediante Kubernetes.
- Una KNF:access, que se conecta a la red de acceso y permitir√≠a clasificar el tr√°fico e implementar QoS en el acceso del usuario a la red.
- Una KNF:arpwatch,
- Una KNF:vcpe, que integrar√° las funciones de servidor DHCP, NAT y reenv√≠o de IP.

![Escenario](https://github.com/jvelazquezm/repo-rdsv/blob/main/escenario/escenario.jpg)

Adem√°s, hay que tener en cuenta que:

- Se utiliza la tecnolog√≠a VXLAN para enviar encapsuladas en datagramas UDP las tramas de nivel 2 que viajan entre brg1, KNF:access, KNF:arpwatch y KNF:cpe. 
- La asignaci√≥n de direcciones IP a las KNF's est√° gestionada por OSM y k8s, de manera que se asignan din√°micamente al instanciar las KNFs.

## Despliegue del entorno üöÄ

A continuaci√≥n, se presentan los pasos a seguir para inicializar ambas redes residenciales virtualizadas con OSM con los requisitos m√≠nimos y opcionales que han sido realizados.

### Pasos previos üîß

- Iniciar las dos m√°quinas virtuales en el laboratorio o en el ordenador personal: `RDSV-K8S | RDSV-OSM`
- Acceder al directorio compartido y clonar el repositorio en ambas m√°quinas con el comando:
```
cd shared
git clone https://github.com/jvelazquezm/repo-rdsv.git
```
- Comprobar que scripts que se van a ejecutar cuentan con permisos de ejecuci√≥n. En caso contrario, ejecutar:
```
chmod +x <nombre_script.sh>
```
- Modificar las im√°genes utilizadas por VNX para que incluyan iperf3 para las pruebas de QoS. Para ello ejecutar el siguiente comando, hacer login con root/xxxx e instalar los paquetes deseados. Finalmente, parar el contenedor con `halt -p`.
```
vnx --modify-rootfs /usr/share/vnx/filesystems/vnx_rootfs_lxc_ubuntu64-20.04-v025-vnxlab/
```
- En la m√°quina de OSM compruebe que tiene configurado un cluster de k8s mediante el comando:
```
osm k8scluster-list
```

### Despliegue en RDSV-K8S üèπ

- Entramos dentro de la carpeta del repositorio mediante el comando:
```
cd repo-rsdv
```
- Ejecutamos el script de creaci√≥n del escenario, init_k8s.sh:
```
./init_k8s.sh
```

### Despliegue en RDSV-OSMüèπ

- Entramos dentro de la carpeta del repositorio mediante el comando:
```
cd repo-rsdv
```
- Ejecutamos el script de creaci√≥n del escenario, init_osm.sh, con el formato indicado, para que exporte bien las variables:
```
. init_osm.sh
```
- Ejecutamos el script de creaci√≥n de las instancias de renes de las dos redes residenciales, osm_renes_all.sh, pasandole la variable indicada:
```
./osm_renes_all.sh $OSMNS
```
- En este punto debemos esperar a que el servidor DHCP asigne a los hosts la ip. Para comprobar que se ha realizado, en la m√°quina RDSV-K8S, en la terminal de cada uno de ellos, ejecutamos:
```
ifconfig
```
- Ejecutamos el script de configuraci√≥n de la QoS descendente y ascendente para las dos redes residenciales, apply_qos_all.sh.
```
./apply_qos_all.sh $OSMNS
```

## Pruebas de conectividad, calidad de servicio y arpwatch

- Para probar la conectividad IPv4 desde la red residencial hacia Internet realizamos el siguiente ping desde cada uno los hosts, en la m√°quina RDSV-K8S:
```
ping 8.8.8.8
```
- Para probar la calidad de servicio, se hace uso de la herramienta iperf3. Para ello, se realizan pruebas desde diversas m√°quinas y debemos tener en cuenta que se debe cumplir lo siguiente: 
    - Para la red residencial: 12 Mbps de bajada (y 6 Mbps de subida)
    - Para hX1: 8 Mbps m√≠nimo de bajada (y 4 Mbps m√≠nimo de subida)
    - Para hX2: 4 Mbps m√°ximo de bajada (y 2 Mbps m√°ximo de subida)
```

```
- Para probar la funcionalidad del arpwatch, comprobamos que el registro de las MACs de la red residencial. Para ello, debemos realizar:
```
kubectl exec -n $OSMNS $VARP -- /bin/bash
cat /etc/default/arpwatch/brint.dat
cat /etc/default/arpwatch/eth0.dat
```

## Posibles errores a tener en cuenta

- Cuando se ejecute el script init_osm.sh, es posible que la instacia de renes no se cree bien la primera vez. Esto se debe a errores de la m√°quina virtual con el software OSM que tiene instalado. Basta con destruir el escenario con el script destroy_osm.sh y volver a ejecutar el init_osm.sh

- Nunca deben iniciarse los scripts de aplicar QoS sin que se hayan asignado las IPs a los hosts de las redes residenciales, ya que esto inducir√≠a a error. Siempre comprobarlo antes de ejecutar.

## Destrucci√≥n del entorno üí£

### RDSV-K8S 

- Ejecutamos el script de creaci√≥n del escenario, destroy_k8s.sh:
```
./destroy_k8s.sh
```

### RDSV-OSM 

- Ejecutamos el script de creaci√≥n del escenario, destroy_osm.sh:
```
./destroy_osm.sh
```
